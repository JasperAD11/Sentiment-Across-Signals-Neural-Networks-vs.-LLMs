{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "55d31e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import whisper\n",
    "import pyaudio\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import threading\n",
    "import time\n",
    "import wave\n",
    "import model\n",
    "from datetime import datetime\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.layers import TextVectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3aa4899b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Recording... Press Ctrl+C to stop and transcribe\n",
      "\n",
      "* Stopping recording...\n",
      "* Saving audio to recording_20250522_130344.wav...\n",
      "* Audio saved as recording_20250522_130344.wav\n",
      "* Processing audio with Whisper...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "FULL TRANSCRIPTION:\n",
      "==================================================\n",
      " This movie was really really bad. I never saw something as shitty as this.\n",
      "==================================================\n",
      "* Transcription saved as transcription_20250522_130344.txt\n",
      "\n",
      "* Starting text classification...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 205ms/step\n",
      "\n",
      "==================================================\n",
      "CLASSIFICATION RESULTS:\n",
      "==================================================\n",
      "sentiment: positive\n",
      "emotion: ['approval']\n",
      "==================================================\n",
      "* Classification results saved as classification_20250522_130344.txt\n",
      "* Process completed\n"
     ]
    }
   ],
   "source": [
    "# Load Whisper model\n",
    "whisper_model = whisper.load_model(\"base\")\n",
    "\n",
    "# Setup audio parameters\n",
    "CHUNK = 1024\n",
    "FORMAT = pyaudio.paInt16\n",
    "CHANNELS = 1\n",
    "RATE = 16000\n",
    "\n",
    "# Initialize PyAudio\n",
    "p = pyaudio.PyAudio()\n",
    "all_audio_data = []\n",
    "recording_lock = threading.Lock()\n",
    "stop_recording = threading.Event()\n",
    "\n",
    "# Generate filename with timestamp\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "audio_filename = f\"recording_{timestamp}.wav\"\n",
    "\n",
    "# Open stream\n",
    "stream = p.open(format=FORMAT,\n",
    "                channels=CHANNELS,\n",
    "                rate=RATE,\n",
    "                input=True,\n",
    "                frames_per_buffer=CHUNK)\n",
    "\n",
    "def record_audio():\n",
    "    \"\"\"Record audio continuously until stopped\"\"\"\n",
    "    print(\"* Recording... Press Ctrl+C to stop and transcribe\")\n",
    "    \n",
    "    while not stop_recording.is_set():\n",
    "        try:\n",
    "            data = stream.read(CHUNK, exception_on_overflow=False)\n",
    "            with recording_lock:\n",
    "                all_audio_data.append(data)\n",
    "        except Exception as e:\n",
    "            print(f\"Audio recording error: {e}\")\n",
    "            break\n",
    "\n",
    "# Start recording thread\n",
    "recording_thread = threading.Thread(target=record_audio, daemon=True)\n",
    "recording_thread.start()\n",
    "\n",
    "try:\n",
    "    # Keep main thread alive while recording\n",
    "    while True:\n",
    "        time.sleep(0.1)\n",
    "        \n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\n* Stopping recording...\")\n",
    "    stop_recording.set()\n",
    "\n",
    "# Wait for recording thread to finish\n",
    "recording_thread.join(timeout=1)\n",
    "\n",
    "# Clean up audio stream\n",
    "stream.stop_stream()\n",
    "stream.close()\n",
    "p.terminate()\n",
    "\n",
    "# Save audio file and transcribe\n",
    "if all_audio_data:\n",
    "    print(f\"* Saving audio to {audio_filename}...\")\n",
    "    try:\n",
    "        with wave.open(audio_filename, 'wb') as wf:\n",
    "            wf.setnchannels(CHANNELS)\n",
    "            wf.setsampwidth(p.get_sample_size(FORMAT))\n",
    "            wf.setframerate(RATE)\n",
    "            wf.writeframes(b''.join(all_audio_data))\n",
    "        print(f\"* Audio saved as {audio_filename}\")\n",
    "    except Exception as e:\n",
    "        print(f\"* Error saving audio: {e}\")\n",
    "    \n",
    "    # Convert audio data for Whisper\n",
    "    print(\"* Processing audio with Whisper...\")\n",
    "    try:\n",
    "        # Combine all audio chunks\n",
    "        combined_audio = b''.join(all_audio_data)\n",
    "        \n",
    "        # Convert to numpy array for Whisper\n",
    "        audio_np = np.frombuffer(combined_audio, dtype=np.int16).astype(np.float32) / 32768.0\n",
    "        \n",
    "        # Transcribe the entire recording\n",
    "        result = whisper_model.transcribe(audio_np)\n",
    "        transcribed_text = result['text']\n",
    "        \n",
    "        # Display results\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(\"FULL TRANSCRIPTION:\")\n",
    "        print(\"=\"*50)\n",
    "        print(transcribed_text)\n",
    "        print(\"=\"*50)\n",
    "        \n",
    "        # Save transcription to text file\n",
    "        txt_filename = f\"transcription_{timestamp}.txt\"\n",
    "        with open(txt_filename, 'w', encoding='utf-8') as f:\n",
    "            f.write(transcribed_text)\n",
    "        print(f\"* Transcription saved as {txt_filename}\")\n",
    "\n",
    "        # Text Classification\n",
    "        if transcribed_text.strip():  # Only classify if there's actual text\n",
    "            print(\"\\n* Starting text classification...\")\n",
    "            \n",
    "            # Setup text vectorization\n",
    "            max_vocab = 20000\n",
    "            sequence_len = 300\n",
    "            \n",
    "            vectorizer = TextVectorization(\n",
    "                max_tokens=max_vocab,\n",
    "                output_mode='int',\n",
    "                output_sequence_length=sequence_len\n",
    "            )\n",
    "            \n",
    "            # Note: You need training data to adapt the vectorizer properly\n",
    "            # For now, we'll adapt on the single text (not ideal for production)\n",
    "            vectorizer.adapt([transcribed_text])\n",
    "            \n",
    "            # Load classification models\n",
    "            class_models = model.create_ensemble_model('best_model_binary.h5', 'best_model_multi.h5')\n",
    "            \n",
    "            if class_models:\n",
    "                # Make predictions\n",
    "                final_classification = model.predict_ensemble_model(class_models, [transcribed_text], vectorizer)\n",
    "                \n",
    "                if final_classification:\n",
    "                    print(\"\\n\" + \"=\"*50)\n",
    "                    print(\"CLASSIFICATION RESULTS:\")\n",
    "                    print(\"=\"*50)\n",
    "                    for key, value in final_classification.items():\n",
    "                        print(f\"{key}: {value}\")\n",
    "                    print(\"=\"*50)\n",
    "                    \n",
    "                    # Save classification results\n",
    "                    results_filename = f\"classification_{timestamp}.txt\"\n",
    "                    with open(results_filename, 'w', encoding='utf-8') as f:\n",
    "                        f.write(\"TRANSCRIPTION:\\n\")\n",
    "                        f.write(transcribed_text + \"\\n\\n\")\n",
    "                        f.write(\"CLASSIFICATION RESULTS:\\n\")\n",
    "                        for key, value in final_classification.items():\n",
    "                            f.write(f\"{key}: {value}\\n\")\n",
    "                    print(f\"* Classification results saved as {results_filename}\")\n",
    "            else:\n",
    "                print(\"* Could not load classification models\")\n",
    "        else:\n",
    "            print(\"* No text to classify\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"* Error during transcription: {e}\")\n",
    "else:\n",
    "    print(\"* No audio data recorded\")\n",
    "\n",
    "print(\"* Process completed\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "UCP_APA_2425",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
