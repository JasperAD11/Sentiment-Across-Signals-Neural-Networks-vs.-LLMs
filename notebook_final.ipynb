{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JasperAD11/Sentiment-Across-Signals-Neural-Networks-vs.-LLMs/blob/main/notebook_final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4AeNj0txdNof"
      },
      "source": [
        "# Part 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jWdQVt36dJw3"
      },
      "source": [
        "## Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sdv90RuERAUk"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import os\n",
        "import shutil\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, models, initializers\n",
        "from tensorflow.keras.models import Model, load_model\n",
        "from tensorflow.keras.layers import TextVectorization, Input, Embedding, LSTM, Dropout, Dense\n",
        "from tensorflow.keras.initializers import Constant\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DdOsEDOmS2GP"
      },
      "source": [
        "## Binary model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zRRWrFkuXuPL"
      },
      "source": [
        "### Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zYev4KopQqyO",
        "outputId": "d7fd0b64-e837-433c-b28b-f5119179ab29"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 80.2M  100 80.2M    0     0  38.0M      0  0:00:02  0:00:02 --:--:-- 38.0M\n"
          ]
        }
      ],
      "source": [
        "!curl -O https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
        "!tar -xzf aclImdb_v1.tar.gz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rVgVZipkQtOG",
        "outputId": "ee590b93-ad54-4415-ffd7-7644b23bca7b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 25000 files belonging to 2 classes.\n",
            "Using 20000 files for training.\n",
            "Found 25000 files belonging to 2 classes.\n",
            "Using 5000 files for validation.\n",
            "Found 25000 files belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "# Directory path\n",
        "dataset_dir = \"aclImdb\"\n",
        "\n",
        "# Remove unsup data (not labeled)\n",
        "shutil.rmtree(os.path.join(dataset_dir, 'train', 'unsup'))\n",
        "\n",
        "# Load training and test sets\n",
        "batch_size = 32\n",
        "seed = 42\n",
        "\n",
        "train_ds = tf.keras.utils.text_dataset_from_directory(\n",
        "    os.path.join(dataset_dir, \"train\"),\n",
        "    batch_size=batch_size,\n",
        "    validation_split=0.2,\n",
        "    subset=\"training\",\n",
        "    seed=seed\n",
        ")\n",
        "\n",
        "val_ds = tf.keras.utils.text_dataset_from_directory(\n",
        "    os.path.join(dataset_dir, \"train\"),\n",
        "    batch_size=batch_size,\n",
        "    validation_split=0.2,\n",
        "    subset=\"validation\",\n",
        "    seed=seed\n",
        ")\n",
        "\n",
        "test_ds = tf.keras.utils.text_dataset_from_directory(\n",
        "    os.path.join(dataset_dir, \"test\"),\n",
        "    batch_size=batch_size\n",
        ")\n",
        "\n",
        "# To train the Final Model\n",
        "full_train_ds = train_ds.concatenate(val_ds).shuffle(10000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PRCY6qy3Qx4h"
      },
      "outputs": [],
      "source": [
        "max_vocab = 20000\n",
        "sequence_len = 300\n",
        "\n",
        "vectorizer = TextVectorization(\n",
        "    max_tokens=max_vocab,\n",
        "    output_mode='int',\n",
        "    output_sequence_length=sequence_len\n",
        ")\n",
        "\n",
        "# Adapt vectorizer on training data\n",
        "text_only_train = train_ds.map(lambda x, y: x)\n",
        "vectorizer.adapt(text_only_train)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert datasets to NumPy arrays or tensors\n",
        "def vectorize_dataset(ds):\n",
        "    return ds.map(lambda x, y: (vectorizer(x), y)).cache().prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "\n",
        "train_ds = vectorize_dataset(train_ds)\n",
        "val_ds = vectorize_dataset(val_ds)\n",
        "test_ds = vectorize_dataset(test_ds)\n",
        "full_train_ds = vectorize_dataset(full_train_ds)\n"
      ],
      "metadata": {
        "id": "FpQSe_LYGOoj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "keKdu_WkjTEn"
      },
      "source": [
        "### Final Binary Model (model 2 in notebook1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bQvcBwb_pV4F"
      },
      "outputs": [],
      "source": [
        "model_binary = keras.Sequential([\n",
        "    layers.Embedding(input_dim=max_vocab, output_dim=128),\n",
        "    layers.GlobalAveragePooling1D(),  # Sequence → single vector    TEST WITHOUT\n",
        "\n",
        "    # Dense layer 1\n",
        "    layers.Dense(8, activation='relu'),\n",
        "\n",
        "    # Dense layer 2\n",
        "    layers.Dense(8, activation='relu'),\n",
        "\n",
        "    # Dense layer 3 (Output)\n",
        "    layers.Dense(1, activation='sigmoid')  # Binary classification\n",
        "])\n",
        "\n",
        "model_binary.compile(\n",
        "    optimizer='adam',\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "_xoBVZlXjrvu",
        "outputId": "9c0534f0-15b9-42d1-e99e-f690362bce96"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m780/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5872 - loss: 0.6363"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/callbacks/early_stopping.py:153: UserWarning: Early stopping conditioned on metric `val_AUC` which is not available. Available metrics are: accuracy,loss,val_accuracy,val_loss\n",
            "  current = self.get_monitor_value(logs)\n",
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.5876 - loss: 0.6359 - val_accuracy: 0.8264 - val_loss: 0.3757\n",
            "Epoch 2/20\n",
            "\u001b[1m770/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8673 - loss: 0.3148"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.8675 - loss: 0.3144 - val_accuracy: 0.8604 - val_loss: 0.3282\n",
            "Epoch 3/20\n",
            "\u001b[1m764/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9003 - loss: 0.2486"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9005 - loss: 0.2481 - val_accuracy: 0.8715 - val_loss: 0.3158\n",
            "Epoch 4/20\n",
            "\u001b[1m777/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9194 - loss: 0.2094"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9195 - loss: 0.2093 - val_accuracy: 0.8749 - val_loss: 0.3236\n",
            "Epoch 5/20\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.9194 - loss: 0.2097 - val_accuracy: 0.8524 - val_loss: 0.4011\n",
            "Epoch 6/20\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9268 - loss: 0.1908 - val_accuracy: 0.8220 - val_loss: 0.5351\n",
            "Epoch 7/20\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.9455 - loss: 0.1509 - val_accuracy: 0.8386 - val_loss: 0.5300\n",
            "Epoch 8/20\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.9451 - loss: 0.1515 - val_accuracy: 0.7966 - val_loss: 0.7192\n",
            "Epoch 9/20\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.9381 - loss: 0.1568 - val_accuracy: 0.7684 - val_loss: 0.9421\n",
            "Epoch 10/20\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.9433 - loss: 0.1517 - val_accuracy: 0.7776 - val_loss: 0.9389\n",
            "Epoch 11/20\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9531 - loss: 0.1270 - val_accuracy: 0.7861 - val_loss: 0.8590\n",
            "Epoch 12/20\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9446 - loss: 0.1421 - val_accuracy: 0.8055 - val_loss: 0.7191\n",
            "Epoch 13/20\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.9461 - loss: 0.1442 - val_accuracy: 0.8613 - val_loss: 0.5406\n",
            "Epoch 14/20\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.9506 - loss: 0.1340 - val_accuracy: 0.8647 - val_loss: 0.6043\n",
            "Epoch 15/20\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9496 - loss: 0.1282 - val_accuracy: 0.8448 - val_loss: 0.6492\n",
            "Epoch 16/20\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9494 - loss: 0.1323 - val_accuracy: 0.8413 - val_loss: 0.6277\n",
            "Epoch 17/20\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9656 - loss: 0.0938 - val_accuracy: 0.8272 - val_loss: 0.6316\n",
            "Epoch 18/20\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9638 - loss: 0.0955 - val_accuracy: 0.8476 - val_loss: 0.6912\n",
            "Epoch 19/20\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9696 - loss: 0.0832 - val_accuracy: 0.8406 - val_loss: 0.6619\n",
            "Epoch 20/20\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9735 - loss: 0.0733 - val_accuracy: 0.8450 - val_loss: 0.6203\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_3\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_3 (\u001b[38;5;33mEmbedding\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │     \u001b[38;5;34m2,560,000\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ global_average_pooling1d_1      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)        │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │         \u001b[38;5;34m1,032\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_9 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │            \u001b[38;5;34m72\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_10 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │             \u001b[38;5;34m9\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,560,000</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ global_average_pooling1d_1      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)        │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,032</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m7,683,341\u001b[0m (29.31 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,683,341</span> (29.31 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,561,113\u001b[0m (9.77 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,561,113</span> (9.77 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m5,122,228\u001b[0m (19.54 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,122,228</span> (19.54 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "history = model_binary.fit(\n",
        "    full_train_ds,\n",
        "    validation_data = test_ds,\n",
        "    epochs=20,\n",
        "    callbacks = [\n",
        "        EarlyStopping(monitor='val_AUC', patience=10, restore_best_weights=True, mode='max'),\n",
        "        ModelCheckpoint('best_model_binary.h5', monitor='val_accuracy', save_best_only=True, mode='max')]\n",
        ")\n",
        "\n",
        "model_binary.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aUUi8qM-X3_J"
      },
      "source": [
        "## Multi-class model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jj8HI6SJYBNC"
      },
      "source": [
        "### Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IK9dIE9fYEmM",
        "outputId": "f0b40bf2-fce9-43b6-8240-dd28025ab8ee",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  emotions-goemotions.zip\n",
            "   creating: emotions_data/goemotions/\n",
            "  inflating: emotions_data/goemotions/.DS_Store  \n",
            "  inflating: emotions_data/__MACOSX/goemotions/._.DS_Store  \n",
            "   creating: emotions_data/goemotions/data/\n",
            "  inflating: emotions_data/__MACOSX/goemotions/._data  \n",
            "  inflating: emotions_data/goemotions/data/.DS_Store  \n",
            "  inflating: emotions_data/__MACOSX/goemotions/data/._.DS_Store  \n",
            "   creating: emotions_data/goemotions/data/full_dataset/\n",
            "  inflating: emotions_data/__MACOSX/goemotions/data/._full_dataset  \n",
            "  inflating: emotions_data/goemotions/data/full_dataset/goemotions_1.csv  \n",
            "  inflating: emotions_data/__MACOSX/goemotions/data/full_dataset/._goemotions_1.csv  \n",
            "  inflating: emotions_data/goemotions/data/full_dataset/goemotions_3.csv  \n",
            "  inflating: emotions_data/goemotions/data/full_dataset/goemotions_2.csv  \n"
          ]
        }
      ],
      "source": [
        "# Unzip to a folder\n",
        "!unzip emotions-goemotions.zip -d emotions_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XjCs-rBbh60e"
      },
      "outputs": [],
      "source": [
        "dataset = pd.read_csv('emotions_data/goemotions/data/full_dataset/goemotions_1.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P8AML6u7iWus"
      },
      "outputs": [],
      "source": [
        "dataset.drop(columns=[\"id\",\"author\",\"subreddit\",\"link_id\",\"parent_id\",\"created_utc\",\"rater_id\",\"example_very_unclear\"], inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OFGgNap5iaYi"
      },
      "outputs": [],
      "source": [
        "X = vectorizer(dataset['text'].values)\n",
        "\n",
        "y = dataset.drop(columns=['text'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7JjuYQ34i2Sf"
      },
      "outputs": [],
      "source": [
        "X_numpy = X.numpy() if isinstance(X, tf.Tensor) else X\n",
        "X_train_full, X_test, y_train_full, y_test = train_test_split(X_numpy, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Second split: Take 20% of training for validation (16% of original)\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X_train_full,\n",
        "    y_train_full,\n",
        "    test_size=0.2,\n",
        "    random_state=42\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7VLjMbEwCEGJ"
      },
      "source": [
        "### Final Multi-class Model (model 5 in notebook1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YLh1oPPSCnt6"
      },
      "outputs": [],
      "source": [
        "model_multi_class = keras.Sequential([\n",
        "    layers.Embedding(input_dim=max_vocab, output_dim=128),\n",
        "    layers.GlobalAveragePooling1D(),\n",
        "\n",
        "    layers.Dense(128, activation='relu'),\n",
        "    layers.Dropout(0.2),\n",
        "\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dropout(0.2),\n",
        "\n",
        "    layers.Dense(28, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model_multi_class.compile(optimizer='adam',\n",
        "               loss='binary_crossentropy',\n",
        "               metrics=['AUC'])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model_multi_class.fit(X_train_full,\n",
        "                                y_train_full,\n",
        "                                epochs=50,\n",
        "                                batch_size=32,\n",
        "                                validation_data=(X_val, y_val),\n",
        "                                callbacks = [\n",
        "                                    EarlyStopping(monitor='val_AUC', patience=10, restore_best_weights=True),\n",
        "                                    ModelCheckpoint('best_model_multi.h5', monitor='val_AUC', save_best_only=True, mode='max')]\n",
        ")\n",
        "model_multi_class.summary()"
      ],
      "metadata": {
        "id": "fH0-eKE9kBR_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NhkhEzOfNwNz"
      },
      "source": [
        "## Merging **Binary** and **Multi class** models"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_ensemble_model(sentiment_model_path, emotion_model_path):\n",
        "    # Load the models\n",
        "    sentiment_model = load_model(sentiment_model_path)\n",
        "    emotion_model = load_model(emotion_model_path)\n",
        "\n",
        "    # Freeze the models to prevent training\n",
        "    sentiment_model.trainable = False\n",
        "    emotion_model.trainable = False\n",
        "\n",
        "    # Define new input layers\n",
        "    sentiment_input = Input(shape=sentiment_model.input_shape[1:], name=\"sentiment_input\")\n",
        "    emotion_input = Input(shape=emotion_model.input_shape[1:], name=\"emotion_input\")\n",
        "\n",
        "    # Pass the inputs through the respective models\n",
        "    sentiment_output = sentiment_model(sentiment_input)\n",
        "    emotion_output = emotion_model(emotion_input)\n",
        "\n",
        "    # Create the joint model\n",
        "    joint_model = Model(\n",
        "        inputs=[sentiment_input, emotion_input],\n",
        "        outputs=[sentiment_output, emotion_output]\n",
        "    )\n",
        "\n",
        "    return joint_model"
      ],
      "metadata": {
        "id": "scVXHaTxdGGu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "joint_model=create_ensemble_model('best_model_binary.h5', 'best_model_multi.h5')\n",
        "\n",
        "joint_model.summary()"
      ],
      "metadata": {
        "id": "_jSofNKUdL93"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_ensemble_model(model, texts, vectorizer, emotion_labels=emotion_labels, max_length=300, neutral_threshold=0.3, emotion_threshold=0.15):\n",
        "    # Tokenize and pad the input texts\n",
        "    input = vectorizer(texts)\n",
        "\n",
        "    # Make predictions with the joint model\n",
        "    predictions = model.predict({\n",
        "        'sentiment_input': input,\n",
        "        'emotion_input': input\n",
        "    })\n",
        "\n",
        "    # Get the sentiment prediction\n",
        "    sentiment_prediction = predictions[0]\n",
        "\n",
        "    # Convert sentiment prediction to 'positive' or 'negative' based on threshold of 0.5\n",
        "    sentiment_label = \"positive\" if sentiment_prediction[0] > 0.5 else \"negative\"\n",
        "\n",
        "    # Get emotion predictions\n",
        "    emotion_predictions = predictions[1]\n",
        "\n",
        "    # Define emotion labels (adjust to your actual labels)\n",
        "    emotion_labels = ['admiration', 'amusement', 'anger', 'annoyance', 'approval', 'caring', 'confusion', 'curiosity',\n",
        "                      'desire', 'disappointment', 'disapproval', 'disgust', 'embarrassment', 'excitement', 'fear',\n",
        "                      'gratitude', 'grief', 'joy', 'love', 'nervousness', 'optimism', 'pride', 'realization', 'relief',\n",
        "                      'remorse', 'sadness', 'surprise', 'neutral']\n",
        "\n",
        "    # Map the emotion predictions to the emotion labels\n",
        "    emotion_results = {emotion_labels[i]: emotion_predictions[0][i] for i in range(len(emotion_labels))}\n",
        "\n",
        "    # Check if 'neutral' emotion has score > neutral_threshold\n",
        "    if emotion_results.get('neutral', 0) >= neutral_threshold:\n",
        "        # If neutral is above the threshold, only return \"neutral\"\n",
        "        return {\n",
        "            'sentiment': sentiment_label,\n",
        "            'emotion': ['neutral']\n",
        "        }\n",
        "\n",
        "    # Filter emotions: return all emotions > emotion_threshold, excluding 'neutral'\n",
        "    filtered_emotions = {emotion: score for emotion, score in emotion_results.items() if score > emotion_threshold and emotion != 'neutral'}\n",
        "\n",
        "    # If no emotions are above the threshold, return only the emotion with the highest score, excluding 'neutral'\n",
        "    if not filtered_emotions:\n",
        "        max_emotion = max((emotion_results[key], key) for key in emotion_results if key != 'neutral')\n",
        "        filtered_emotions = {max_emotion[1]: max_emotion[0]}\n",
        "\n",
        "    # Return the predictions\n",
        "    return {\n",
        "        'sentiment': sentiment_label,  # Sentiment prediction as 'positive' or 'negative'\n",
        "        'emotion': list(filtered_emotions.keys())  # List of emotions above threshold or best emotion\n",
        "    }\n"
      ],
      "metadata": {
        "id": "l-yupvgcdbxh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predict_ensemble_model(joint_model, [\"I am so excited!\"], vectorizer)"
      ],
      "metadata": {
        "id": "UO_zLxj1gjZd"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "DdOsEDOmS2GP",
        "zRRWrFkuXuPL",
        "I9_UG5OJS-1W",
        "uGA36eK2TENY",
        "BNHl_kMrUxZL"
      ],
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}