{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "1xBPq0Mm5Knt",
        "Gbajqz7JY0Bb",
        "c5GgOPl07z5w",
        "2fTFHeo-5qgK"
      ],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNsk41N0YN2RwyEx5pKa6W0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JasperAD11/Sentiment-Across-Signals-Neural-Networks-vs.-LLMs/blob/main/project_ATPA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**TO DO**:\n",
        "  1. Compute results for other models (change parameters) and compare.\n",
        "  2. Code doesn't run for the second model\n",
        "\n",
        "**Doubts**:\n",
        "  1. what if the same word appears 2x in the same review/newswire, is that explicit in the tensor?"
      ],
      "metadata": {
        "id": "YwcdhsMlEhLz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Project: Part 1"
      ],
      "metadata": {
        "id": "253PasrCyWx1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Functions and libraries needed"
      ],
      "metadata": {
        "id": "cGHnFVplieGp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Importing libraries"
      ],
      "metadata": {
        "id": "tQo3udH5y7eW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os, pathlib, shutil, random\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers import Embedding, TextVectorization, LSTM, Dense, Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n"
      ],
      "metadata": {
        "id": "LSWHjvHfTxHI"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set a fixed random seed value\n",
        "SEED = 42\n",
        "\n",
        "np.random.seed(SEED)\n",
        "tf.random.set_seed(SEED)"
      ],
      "metadata": {
        "id": "YkpF8X_JT2xl"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Vectorizing text inputs"
      ],
      "metadata": {
        "id": "lr2xnVMXlcBQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Vectorizing text\n",
        "# text_vectorization = TextVectorization(\n",
        "#     max_tokens=20000,\n",
        "#     output_mode=\"multi_hot\",\n",
        "# )\n",
        "\n",
        "text_vectorization = layers.TextVectorization(\n",
        "    max_tokens=20000,\n",
        "    output_mode='int',\n",
        "    output_sequence_length=256\n",
        ")"
      ],
      "metadata": {
        "id": "e7yI10dcks_q"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Pre-trained embedding layer - GloVe"
      ],
      "metadata": {
        "id": "K56CFuROlhCF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Run only once\n",
        "!wget http://nlp.stanford.edu/data/glove.6B.zip"
      ],
      "metadata": {
        "id": "2mnQYcd0wjdY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd8fdc7f-6e80-4d53-8052-13ca03f64934"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-05-05 16:06:46--  http://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
            "--2025-05-05 16:06:46--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
            "--2025-05-05 16:06:47--  https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip’\n",
            "\n",
            "glove.6B.zip        100%[===================>] 822.24M  5.11MB/s    in 2m 40s  \n",
            "\n",
            "2025-05-05 16:09:28 (5.13 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Run only once\n",
        "!unzip -q glove.6B.zip"
      ],
      "metadata": {
        "id": "Nf-0RRwswpcM"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading pre-trained word embedding (GloVe)   PAGE 333 BOOK\n",
        "path_to_glove_file = \"glove.6B.100d.txt\"\n",
        "\n",
        "embeddings_index = {}\n",
        "with open(path_to_glove_file) as f:\n",
        "  for line in f:\n",
        "    word, coefs = line.split(maxsplit=1)\n",
        "    coefs = np.fromstring(coefs, \"f\", sep=\" \")\n",
        "    embeddings_index[word] = coefs\n",
        "\n",
        "print(f\"Found {len(embeddings_index)} word vectors.\")"
      ],
      "metadata": {
        "id": "6fDeMZqPiiQ_",
        "outputId": "88ee2f4e-d396-46cf-eb0d-5f4ad50d62d9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 400000 word vectors.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_dim = 100\n",
        "max_tokens = 20000\n",
        "\n",
        "vocabulary = text_vectorization.get_vocabulary()\n",
        "word_index = dict(zip(vocabulary, range(len(vocabulary))))\n",
        "\n",
        "# vocab = vectorizer.get_vocabulary()\n",
        "# word_index = {word: idx for idx, word in enumerate(vocab)}\n",
        "\n",
        "embedding_matrix = np.zeros((max_tokens, embedding_dim))\n",
        "for word, i in word_index.items():\n",
        "  if i < max_tokens:\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "  if embedding_vector is not None:\n",
        "    embedding_matrix[i] = embedding_vector\n",
        "\n",
        "embedding_layer = layers.Embedding(\n",
        "    max_tokens,\n",
        "    embedding_dim,\n",
        "    embeddings_initializer=keras.initializers.Constant(embedding_matrix),\n",
        "    trainable=False,\n",
        "    mask_zero=True,\n",
        "    )"
      ],
      "metadata": {
        "id": "ev40BZgsj_E2"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model 1: Binary sentiment classification"
      ],
      "metadata": {
        "id": "ZDVyLJnxWJR0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset\n"
      ],
      "metadata": {
        "id": "1xBPq0Mm5Knt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Run only once\n",
        "!curl -O https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
        "!tar -xf aclImdb_v1.tar.gz\n",
        "!rm -r aclImdb/train/unsup"
      ],
      "metadata": {
        "id": "AhjRy3uztecE",
        "outputId": "83d78438-64a2-4351-ad84-cb23e239813a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 80.2M  100 80.2M    0     0  5044k      0  0:00:16  0:00:16 --:--:-- 11.0M\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_dir = pathlib.Path(\"aclImdb\")\n",
        "\n",
        "val_dir = base_dir / \"val\"\n",
        "train_dir = base_dir / \"train\"\n",
        "\n",
        "for category in (\"neg\", \"pos\"):\n",
        "  os.makedirs(val_dir / category)\n",
        "  files = os.listdir(train_dir / category)\n",
        "  random.Random(1337).shuffle(files)\n",
        "  num_val_samples = int(0.2 * len(files))\n",
        "  val_files = files[-num_val_samples:]\n",
        "  for fname in val_files:\n",
        "    shutil.move(train_dir / category / fname,\n",
        "                val_dir / category / fname)"
      ],
      "metadata": {
        "id": "-dqyV_iJ1GQ7"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "\n",
        "train_ds = keras.utils.text_dataset_from_directory(\n",
        "    \"aclImdb/train\", batch_size=batch_size)\n",
        "\n",
        "val_ds = keras.utils.text_dataset_from_directory(\n",
        "    \"aclImdb/val\", batch_size=batch_size)\n",
        "\n",
        "test_ds = keras.utils.text_dataset_from_directory(\n",
        "    \"aclImdb/test\", batch_size=batch_size)"
      ],
      "metadata": {
        "id": "RdwtePpN2Q5G",
        "outputId": "fab5aed4-9072-4b09-ab68-bb301a60a185",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 20000 files belonging to 2 classes.\n",
            "Found 5000 files belonging to 2 classes.\n",
            "Found 25000 files belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_only_train_ds = train_ds.map(lambda x, y: x)\n",
        "text_vectorization.adapt(text_only_train_ds)\n",
        "\n",
        "binary_1gram_train_ds = train_ds.map(\n",
        "    lambda x, y: (text_vectorization(x), y),\n",
        "    num_parallel_calls=4)\n",
        "\n",
        "binary_1gram_val_ds = val_ds.map(\n",
        "    lambda x, y: (text_vectorization(x), y),\n",
        "    num_parallel_calls=4)\n",
        "\n",
        "binary_1gram_test_ds = test_ds.map(\n",
        "    lambda x, y: (text_vectorization(x), y),\n",
        "    num_parallel_calls=4)"
      ],
      "metadata": {
        "id": "7o97fInk3WTs"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### CNN model - first architecture type"
      ],
      "metadata": {
        "id": "ha9ekmfat7Tq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# USING CHAT GPT\n",
        "\n",
        "model_cnn1 = keras.Sequential([\n",
        "    layers.Input(shape=(None,), dtype=\"int64\"),  # Vectorized text input\n",
        "    layers.Embedding(input_dim=text_vectorization.vocabulary_size(), output_dim=128),\n",
        "    layers.Conv1D(128, 5, activation=\"relu\"),\n",
        "    layers.GlobalMaxPooling1D(),\n",
        "    layers.Dense(64, activation=\"relu\"),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(1, activation=\"sigmoid\")  # Binary output\n",
        "])\n",
        "\n",
        "model_cnn1.compile(\n",
        "    loss=\"binary_crossentropy\",\n",
        "    optimizer=\"adam\",\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "model_cnn1.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 345
        },
        "id": "G2FBnscb_j-5",
        "outputId": "09126bb8-025a-42b8-cdfb-65cfe67fd637"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │     \u001b[38;5;34m2,560,000\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1d (\u001b[38;5;33mConv1D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │        \u001b[38;5;34m82,048\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ global_max_pooling1d            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mGlobalMaxPooling1D\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m65\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,560,000</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">82,048</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ global_max_pooling1d            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalMaxPooling1D</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,650,369\u001b[0m (10.11 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,650,369</span> (10.11 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,650,369\u001b[0m (10.11 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,650,369</span> (10.11 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# early_stopping = EarlyStopping(monitor='val_loss', patience=3)\n",
        "early_stopping = EarlyStopping(monitor='val_accuracy', patience=3)\n",
        "\n",
        "history_cnn1 = model_cnn1.fit(\n",
        "    binary_1gram_train_ds,\n",
        "    validation_data=binary_1gram_val_ds,\n",
        "    epochs=15,\n",
        "    callbacks=[early_stopping]\n",
        ")\n",
        "\n",
        "model_cnn1.evaluate(binary_1gram_test_ds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_8WXB9KV_zHH",
        "outputId": "f2e29d4f-3751-4f75-d569-4beb2ebf6478"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.6607 - loss: 0.5767 - val_accuracy: 0.8680 - val_loss: 0.3108\n",
            "Epoch 2/15\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - accuracy: 0.8889 - loss: 0.2725 - val_accuracy: 0.8752 - val_loss: 0.3051\n",
            "Epoch 3/15\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9689 - loss: 0.0997 - val_accuracy: 0.8818 - val_loss: 0.3675\n",
            "Epoch 4/15\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9962 - loss: 0.0201 - val_accuracy: 0.8784 - val_loss: 0.4472\n",
            "Epoch 5/15\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - accuracy: 0.9990 - loss: 0.0055 - val_accuracy: 0.8784 - val_loss: 0.5277\n",
            "Epoch 6/15\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9992 - loss: 0.0025 - val_accuracy: 0.8820 - val_loss: 0.5622\n",
            "Epoch 7/15\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.9999 - loss: 0.0015 - val_accuracy: 0.8786 - val_loss: 0.6447\n",
            "Epoch 8/15\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.9913 - loss: 0.0255 - val_accuracy: 0.8660 - val_loss: 0.6485\n",
            "Epoch 9/15\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9943 - loss: 0.0155 - val_accuracy: 0.8672 - val_loss: 0.7433\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8605 - loss: 0.7861\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.7815523147583008, 0.8600000143051147]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_cnn2 = keras.Sequential([\n",
        "    layers.Embedding(input_dim=20000, output_dim=128),\n",
        "    layers.GlobalAveragePooling1D(),\n",
        "    layers.Dense(64, activation=\"relu\"),\n",
        "    layers.Dense(1, activation=\"sigmoid\")\n",
        "])\n",
        "\n",
        "model_cnn2.compile(\n",
        "    loss=\"binary_crossentropy\",\n",
        "    optimizer=\"adam\",\n",
        "    metrics=[\"accuracy\"]\n",
        ")"
      ],
      "metadata": {
        "id": "VnpjoExOE6aF"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# early_stopping = EarlyStopping(monitor='val_loss', patience=3)\n",
        "early_stopping = EarlyStopping(monitor='val_accuracy', patience=3)\n",
        "\n",
        "history_cnn2 = model_cnn2.fit(\n",
        "    binary_1gram_train_ds,\n",
        "    validation_data=binary_1gram_val_ds,\n",
        "    epochs=15,\n",
        "    callbacks=[early_stopping]\n",
        ")\n",
        "\n",
        "model_cnn2.evaluate(binary_1gram_test_ds)"
      ],
      "metadata": {
        "id": "XVbBYLfkGIIG",
        "outputId": "64c6fed6-70b3-42ea-cf13-f8fe74e6058e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.6837 - loss: 0.5707 - val_accuracy: 0.8526 - val_loss: 0.3427\n",
            "Epoch 2/15\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8799 - loss: 0.2882 - val_accuracy: 0.8840 - val_loss: 0.2767\n",
            "Epoch 3/15\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - accuracy: 0.9034 - loss: 0.2427 - val_accuracy: 0.8710 - val_loss: 0.2984\n",
            "Epoch 4/15\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9354 - loss: 0.1739 - val_accuracy: 0.8788 - val_loss: 0.3059\n",
            "Epoch 5/15\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.9451 - loss: 0.1488 - val_accuracy: 0.8730 - val_loss: 0.3724\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.8471 - loss: 0.4402\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.4418604373931885, 0.8452399969100952]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Most simple model\n",
        "\n",
        "model_basic = keras.Sequential([\n",
        "    layers.Input(shape=(256,)), # Add an input layer with the expected shape\n",
        "    layers.Dense(8, activation=\"relu\"),     # try 4\n",
        "    layers.Dense(8, activation=\"relu\"),     # try 4\n",
        "    layers.Dense(1, activation=\"sigmoid\")\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model_basic.compile(\n",
        "    optimizer='adam',               # better than rmsprop\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")"
      ],
      "metadata": {
        "id": "mz-uM0-yt_eQ"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "early_stopping = EarlyStopping(monitor='val_loss', patience=3)\n",
        "\n",
        "history_basic = model_basic.fit(\n",
        "    binary_1gram_train_ds,\n",
        "    validation_data=binary_1gram_val_ds,\n",
        "    epochs=15,\n",
        "    callbacks=[early_stopping]\n",
        ")\n",
        "\n",
        "model_basic.evaluate(binary_1gram_test_ds)"
      ],
      "metadata": {
        "id": "GTrR_E_2GTqW",
        "outputId": "51065db7-3abe-4b74-a3c4-831428422925",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.4995 - loss: 208.5882 - val_accuracy: 0.5010 - val_loss: 4.4273\n",
            "Epoch 2/15\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.4956 - loss: 2.7229 - val_accuracy: 0.5002 - val_loss: 2.3885\n",
            "Epoch 3/15\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.4986 - loss: 1.2164 - val_accuracy: 0.5038 - val_loss: 1.5142\n",
            "Epoch 4/15\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.5055 - loss: 0.9215 - val_accuracy: 0.5096 - val_loss: 1.3954\n",
            "Epoch 5/15\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.5033 - loss: 0.8111 - val_accuracy: 0.4996 - val_loss: 1.3885\n",
            "Epoch 6/15\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.5060 - loss: 0.7876 - val_accuracy: 0.5064 - val_loss: 1.0973\n",
            "Epoch 7/15\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.5044 - loss: 0.7623 - val_accuracy: 0.5060 - val_loss: 1.0834\n",
            "Epoch 8/15\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.5034 - loss: 0.7293 - val_accuracy: 0.5072 - val_loss: 1.0558\n",
            "Epoch 9/15\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.5059 - loss: 0.7180 - val_accuracy: 0.4988 - val_loss: 1.0527\n",
            "Epoch 10/15\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.4996 - loss: 0.7142 - val_accuracy: 0.5006 - val_loss: 1.0238\n",
            "Epoch 11/15\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5019 - loss: 0.7076 - val_accuracy: 0.4960 - val_loss: 0.9947\n",
            "Epoch 12/15\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.5053 - loss: 0.6956 - val_accuracy: 0.5008 - val_loss: 0.8310\n",
            "Epoch 13/15\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.5060 - loss: 0.6964 - val_accuracy: 0.5006 - val_loss: 0.8255\n",
            "Epoch 14/15\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.4997 - loss: 0.6983 - val_accuracy: 0.5014 - val_loss: 0.8080\n",
            "Epoch 15/15\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.4979 - loss: 0.6950 - val_accuracy: 0.4996 - val_loss: 0.8061\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.4994 - loss: 0.9272\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.9134668707847595, 0.4997200071811676]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "With model1_cnn we have around 89% val_accuracy."
      ],
      "metadata": {
        "id": "a-UqpJLRHQFL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Functional model (from the book)\n",
        "def get_model(max_tokens=20000, hidden_dim=16):\n",
        "  inputs = keras.Input(shape=(max_tokens,))\n",
        "  x = layers.Dense(hidden_dim, activation=\"relu\")(inputs)\n",
        "  x = layers.Dropout(0.5)(x)\n",
        "  outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "\n",
        "  model = keras.Model(inputs, outputs)\n",
        "\n",
        "  model.compile(optimizer=\"rmsprop\",\n",
        "                loss=\"binary_crossentropy\",\n",
        "                metrics=[\"accuracy\"])\n",
        "  return model"
      ],
      "metadata": {
        "id": "EkXuqKmcCzTY"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model2_cnn = get_model()\n",
        "\n",
        "callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint(\"binary_1gram.keras\",\n",
        "                                    save_best_only=True)\n",
        "    ]\n",
        "\n",
        "history2_cnn = model2_cnn.fit(binary_1gram_train_ds.cache(),\n",
        "                              validation_data=binary_1gram_val_ds.cache(),\n",
        "                              epochs=10,\n",
        "                              callbacks=callbacks)\n",
        "\n",
        "model2_cnn.summary()\n",
        "\n",
        "model2_cnn = keras.models.load_model(\"binary_1gram.keras\")\n",
        "\n",
        "print(f\"Test acc: {model2_cnn.evaluate(binary_1gram_test_ds)[1]:.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Ke4PkLwBL412",
        "outputId": "a5cfcad4-fa81-49f3-8d16-58755f289851"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "InvalidArgumentError",
          "evalue": "Graph execution error:\n\nDetected at node functional_3_1/dense_7_1/MatMul defined at (most recent call last):\n<stack traces unavailable>\nMatrix size-incompatible: In[0]: [32,256], In[1]: [20000,16]\n\nStack trace for op definition: \nFile \"<frozen runpy>\", line 198, in _run_module_as_main\nFile \"<frozen runpy>\", line 88, in _run_code\nFile \"/usr/local/lib/python3.11/dist-packages/colab_kernel_launcher.py\", line 37, in <module>\nFile \"/usr/local/lib/python3.11/dist-packages/traitlets/config/application.py\", line 992, in launch_instance\nFile \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelapp.py\", line 712, in start\nFile \"/usr/local/lib/python3.11/dist-packages/tornado/platform/asyncio.py\", line 205, in start\nFile \"/usr/lib/python3.11/asyncio/base_events.py\", line 608, in run_forever\nFile \"/usr/lib/python3.11/asyncio/base_events.py\", line 1936, in _run_once\nFile \"/usr/lib/python3.11/asyncio/events.py\", line 84, in _run\nFile \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\", line 510, in dispatch_queue\nFile \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\", line 499, in process_one\nFile \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\", line 406, in dispatch_shell\nFile \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\", line 730, in execute_request\nFile \"/usr/local/lib/python3.11/dist-packages/ipykernel/ipkernel.py\", line 383, in do_execute\nFile \"/usr/local/lib/python3.11/dist-packages/ipykernel/zmqshell.py\", line 528, in run_cell\nFile \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 2975, in run_cell\nFile \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\nFile \"/usr/local/lib/python3.11/dist-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\nFile \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3257, in run_cell_async\nFile \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\nFile \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\nFile \"<ipython-input-19-710b878c9345>\", line 8, in <cell line: 0>\nFile \"/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\nFile \"/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 371, in fit\nFile \"/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 219, in function\nFile \"/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 132, in multi_step_on_iterator\nFile \"/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 113, in one_step_on_data\nFile \"/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 57, in train_step\nFile \"/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\nFile \"/usr/local/lib/python3.11/dist-packages/keras/src/layers/layer.py\", line 908, in __call__\nFile \"/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\nFile \"/usr/local/lib/python3.11/dist-packages/keras/src/ops/operation.py\", line 46, in __call__\nFile \"/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\", line 156, in error_handler\nFile \"/usr/local/lib/python3.11/dist-packages/keras/src/models/functional.py\", line 182, in call\nFile \"/usr/local/lib/python3.11/dist-packages/keras/src/ops/function.py\", line 171, in _run_through_graph\nFile \"/usr/local/lib/python3.11/dist-packages/keras/src/models/functional.py\", line 637, in call\nFile \"/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\nFile \"/usr/local/lib/python3.11/dist-packages/keras/src/layers/layer.py\", line 908, in __call__\nFile \"/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\nFile \"/usr/local/lib/python3.11/dist-packages/keras/src/ops/operation.py\", line 46, in __call__\nFile \"/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\", line 156, in error_handler\nFile \"/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py\", line 144, in call\nFile \"/usr/local/lib/python3.11/dist-packages/keras/src/ops/numpy.py\", line 3815, in matmul\nFile \"/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/numpy.py\", line 501, in matmul\n\n\t [[{{node functional_3_1/dense_7_1/MatMul}}]]\n\ttf2xla conversion failed while converting __inference_one_step_on_data_154472[]. Run with TF_DUMP_GRAPH_PREFIX=/path/to/dump/dir and --vmodule=xla_compiler=2 to obtain a dump of the compiled functions.\n\t [[StatefulPartitionedCall]] [Op:__inference_multi_step_on_iterator_154507]",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-710b878c9345>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m     ]\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m history2_cnn = model2_cnn.fit(binary_1gram_train_ds.cache(),\n\u001b[0m\u001b[1;32m      9\u001b[0m                               \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbinary_1gram_val_ds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m                               \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m       \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m   \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m     \u001b[0mkeras_symbolic_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m_is_keras_symbolic_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mkeras_symbolic_tensors\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node functional_3_1/dense_7_1/MatMul defined at (most recent call last):\n<stack traces unavailable>\nMatrix size-incompatible: In[0]: [32,256], In[1]: [20000,16]\n\nStack trace for op definition: \nFile \"<frozen runpy>\", line 198, in _run_module_as_main\nFile \"<frozen runpy>\", line 88, in _run_code\nFile \"/usr/local/lib/python3.11/dist-packages/colab_kernel_launcher.py\", line 37, in <module>\nFile \"/usr/local/lib/python3.11/dist-packages/traitlets/config/application.py\", line 992, in launch_instance\nFile \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelapp.py\", line 712, in start\nFile \"/usr/local/lib/python3.11/dist-packages/tornado/platform/asyncio.py\", line 205, in start\nFile \"/usr/lib/python3.11/asyncio/base_events.py\", line 608, in run_forever\nFile \"/usr/lib/python3.11/asyncio/base_events.py\", line 1936, in _run_once\nFile \"/usr/lib/python3.11/asyncio/events.py\", line 84, in _run\nFile \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\", line 510, in dispatch_queue\nFile \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\", line 499, in process_one\nFile \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\", line 406, in dispatch_shell\nFile \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\", line 730, in execute_request\nFile \"/usr/local/lib/python3.11/dist-packages/ipykernel/ipkernel.py\", line 383, in do_execute\nFile \"/usr/local/lib/python3.11/dist-packages/ipykernel/zmqshell.py\", line 528, in run_cell\nFile \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 2975, in run_cell\nFile \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\nFile \"/usr/local/lib/python3.11/dist-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\nFile \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3257, in run_cell_async\nFile \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\nFile \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\nFile \"<ipython-input-19-710b878c9345>\", line 8, in <cell line: 0>\nFile \"/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\nFile \"/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 371, in fit\nFile \"/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 219, in function\nFile \"/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 132, in multi_step_on_iterator\nFile \"/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 113, in one_step_on_data\nFile \"/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 57, in train_step\nFile \"/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\nFile \"/usr/local/lib/python3.11/dist-packages/keras/src/layers/layer.py\", line 908, in __call__\nFile \"/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\nFile \"/usr/local/lib/python3.11/dist-packages/keras/src/ops/operation.py\", line 46, in __call__\nFile \"/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\", line 156, in error_handler\nFile \"/usr/local/lib/python3.11/dist-packages/keras/src/models/functional.py\", line 182, in call\nFile \"/usr/local/lib/python3.11/dist-packages/keras/src/ops/function.py\", line 171, in _run_through_graph\nFile \"/usr/local/lib/python3.11/dist-packages/keras/src/models/functional.py\", line 637, in call\nFile \"/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\nFile \"/usr/local/lib/python3.11/dist-packages/keras/src/layers/layer.py\", line 908, in __call__\nFile \"/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\nFile \"/usr/local/lib/python3.11/dist-packages/keras/src/ops/operation.py\", line 46, in __call__\nFile \"/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\", line 156, in error_handler\nFile \"/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py\", line 144, in call\nFile \"/usr/local/lib/python3.11/dist-packages/keras/src/ops/numpy.py\", line 3815, in matmul\nFile \"/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/numpy.py\", line 501, in matmul\n\n\t [[{{node functional_3_1/dense_7_1/MatMul}}]]\n\ttf2xla conversion failed while converting __inference_one_step_on_data_154472[]. Run with TF_DUMP_GRAPH_PREFIX=/path/to/dump/dir and --vmodule=xla_compiler=2 to obtain a dump of the compiled functions.\n\t [[StatefulPartitionedCall]] [Op:__inference_multi_step_on_iterator_154507]"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "With model2_cnn we have around 90% val_accuracy."
      ],
      "metadata": {
        "id": "CKXQWbdrWzfL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Plotting:"
      ],
      "metadata": {
        "id": "2fTFHeo-5qgK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Loss\n",
        "history_dict = history1_cnn.history\n",
        "loss_values = history_dict[\"loss\"]\n",
        "val_loss_values = history_dict[\"val_loss\"]\n",
        "epochs = range(1, len(loss_values) + 1)\n",
        "plt.plot(epochs, loss_values, \"bo\", label=\"Training loss\")\n",
        "plt.plot(epochs, val_loss_values, \"b\", label=\"Validation loss\")\n",
        "plt.title(\"CNN 1 - Training and validation loss\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "HbIcLsqa5qBs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Accuracy\n",
        "plt.clf()\n",
        "acc = history_dict[\"accuracy\"]\n",
        "val_acc = history_dict[\"val_accuracy\"]\n",
        "plt.plot(epochs, acc, \"bo\", label=\"Training acc\")\n",
        "plt.plot(epochs, val_acc, \"b\", label=\"Validation acc\")\n",
        "plt.title(\"CNN 1 - Training and validation accuracy\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "6gKiQIBp6AdZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loss\n",
        "history_dict = history2_cnn.history\n",
        "loss_values = history_dict[\"loss\"]\n",
        "val_loss_values = history_dict[\"val_loss\"]\n",
        "epochs = range(1, len(loss_values) + 1)\n",
        "plt.plot(epochs, loss_values, \"bo\", label=\"Training loss\")\n",
        "plt.plot(epochs, val_loss_values, \"b\", label=\"Validation loss\")\n",
        "plt.title(\"CNN 2 - Training and validation loss\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "cqiuN286NZIv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Accuracy\n",
        "plt.clf()\n",
        "acc = history_dict[\"accuracy\"]\n",
        "val_acc = history_dict[\"val_accuracy\"]\n",
        "plt.plot(epochs, acc, \"bo\", label=\"Training acc\")\n",
        "plt.plot(epochs, val_acc, \"b\", label=\"Validation acc\")\n",
        "plt.title(\"CNN 2 - Training and validation accuracy\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "5toUtebENc5l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "-79zCwYbot9J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### LSTM model - second architecture type"
      ],
      "metadata": {
        "id": "BJw5hU5WcIqN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_dim = 100\n",
        "max_tokens = 20000\n",
        "\n",
        "vocabulary = text_vectorization.get_vocabulary()\n",
        "word_index = dict(zip(vocabulary, range(len(vocabulary))))\n",
        "\n",
        "# vocab = vectorizer.get_vocabulary()\n",
        "# word_index = {word: idx for idx, word in enumerate(vocab)}\n",
        "\n",
        "embedding_matrix = np.zeros((max_tokens, embedding_dim))\n",
        "for word, i in word_index.items():\n",
        "  if i < max_tokens:\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "  if embedding_vector is not None:\n",
        "    embedding_matrix[i] = embedding_vector\n",
        "\n",
        "embedding_layer = layers.Embedding(\n",
        "    max_tokens,\n",
        "    embedding_dim,\n",
        "    embeddings_initializer=keras.initializers.Constant(embedding_matrix),\n",
        "    trainable=False,\n",
        "    mask_zero=True,\n",
        "    )"
      ],
      "metadata": {
        "id": "8w0B7JOt6n4g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = keras.Input(shape=(None,), dtype=\"int64\")\n",
        "embedded = embedding_layer(inputs)\n",
        "x = layers.Bidirectional(layers.LSTM(32))(embedded)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "\n",
        "model = keras.Model(inputs, outputs)\n",
        "\n",
        "model.compile(optimizer=\"rmsprop\",\n",
        "              loss=\"binary_crossentropy\",\n",
        "              metrics=[\"accuracy\"])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "callbacks = [\n",
        "keras.callbacks.ModelCheckpoint(\"glove_embeddings_sequence_model.keras\",\n",
        "                                save_best_only=True)\n",
        "]\n",
        "\n",
        "\n",
        "history1_lstm = model.fit(x=binary_1gram_train_ds,\n",
        "                          validation_data=binary_1gram_val_ds,\n",
        "                          epochs=10,\n",
        "                          callbacks=callbacks)\n",
        "\n",
        "\n",
        "model = keras.models.load_model(\"glove_embeddings_sequence_model.keras\")\n",
        "\n",
        "print(f\"Test acc: {model.evaluate(binary_1gram_test_ds)[1]:.3f}\")"
      ],
      "metadata": {
        "id": "PC1BKuhPPo8Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Plotting:"
      ],
      "metadata": {
        "id": "JpJaWaOqeTZQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Loss\n",
        "history_dict = history.history\n",
        "loss_values = history_dict[\"loss\"]\n",
        "val_loss_values = history_dict[\"val_loss\"]\n",
        "epochs = range(1, len(loss_values) + 1)\n",
        "plt.plot(epochs, loss_values, \"bo\", label=\"Training loss\")\n",
        "plt.plot(epochs, val_loss_values, \"b\", label=\"Validation loss\")\n",
        "plt.title(\"Training and validation loss\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "UyFDFh7_eVWx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Accuracy\n",
        "plt.clf()\n",
        "acc = history_dict[\"accuracy\"]\n",
        "val_acc = history_dict[\"val_accuracy\"]\n",
        "plt.plot(epochs, acc, \"bo\", label=\"Training acc\")\n",
        "plt.plot(epochs, val_acc, \"b\", label=\"Validation acc\")\n",
        "plt.title(\"Training and validation accuracy\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "V3js4lg2edsJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Final model"
      ],
      "metadata": {
        "id": "XsxCCIe4eLUN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Retraining the model in all the train data and evaluation in test data.\n",
        "After that we are computing the results."
      ],
      "metadata": {
        "id": "4h7LCl3387b2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "history = model_lstm.fit(\n",
        "    x_train, y_train,\n",
        "    batch_size=32,\n",
        "    epochs=10,\n",
        "    validation_split=0.2,\n",
        "    callbacks=[\n",
        "        keras.callbacks.EarlyStopping(monitor='val_loss', patience=2),\n",
        "        keras.callbacks.ModelCheckpoint('best_lstm_model.h5', save_best_only=True)\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "g__PxA31eChT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.Sequential([\n",
        "    ])\n",
        "\n",
        "model.compile(optimizer=,\n",
        "              loss=,\n",
        "              metrics=)\n",
        "\n",
        "model.fit(x_train, y_train, epochs=4, batch_size=512)\n",
        "\n",
        "results = model.evaluate(x_test, y_test)\n",
        "\n",
        "results"
      ],
      "metadata": {
        "id": "8rWiEv_R8gWj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Making predictions:"
      ],
      "metadata": {
        "id": "XKHebbUuFrgr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.predict(x_test)"
      ],
      "metadata": {
        "id": "ZkAwATljFvFy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Can we improve the model? How?"
      ],
      "metadata": {
        "id": "O5nswqwWGII7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We experiment different architecture:\n",
        "1. Add another layer / Take out one layer.\n",
        "2. Increse/Decrease perceptrons inside layers (usualy factors of 8: 32, 64, 128).\n",
        "3. Try 'mse' for loss function.\n",
        "4. Try 'tanh' for activation function."
      ],
      "metadata": {
        "id": "Xmuc3FDbGQMR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Model that uses pre trained embedding (book)\n",
        "inputs = keras.Input(shape=(None,), dtype=\"int64\")\n",
        "embedded = embedding_layer(inputs)\n",
        "x = layers.Bidirectional(layers.LSTM(32))(embedded)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model = keras.Model(inputs, outputs)\n",
        "model.compile(optimizer=\"rmsprop\",\n",
        "loss=\"binary_crossentropy\",\n",
        "metrics=[\"accuracy\"])\n",
        "model.summary()\n",
        "callbacks = [\n",
        "keras.callbacks.ModelCheckpoint(\"glove_embeddings_sequence_model.keras\",\n",
        "save_best_only=True)\n",
        "]\n",
        "model.fit(int_train_ds, validation_data=int_val_ds, epochs=10,\n",
        "callbacks=callbacks)\n",
        "model = keras.models.load_model(\"glove_embeddings_sequence_model.keras\")\n",
        "print(f\"Test acc: {model.evaluate(int_test_ds)[1]:.3f}\")"
      ],
      "metadata": {
        "id": "_TDnqDhXhtZ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  Model 2: Multi-class emotion detection"
      ],
      "metadata": {
        "id": "USMhtAQieuXS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.datasets import reuters   # Dataset with news labeled with a topic"
      ],
      "metadata": {
        "id": "Bt8Vp8V4kVUm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset"
      ],
      "metadata": {
        "id": "9paB0SWChMi0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "(using reuters dataset inside tensorflow.keras.datasets)"
      ],
      "metadata": {
        "id": "YQd8r27OfR2h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_1= pd.read_csv(\"goemotions_1.csv\")\n",
        "df_2= pd.read_csv(\"goemotions_2.csv\")\n",
        "df_3= pd.read_csv(\"goemotions_3.csv\")"
      ],
      "metadata": {
        "id": "O8EYGGl0smFH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(train_data, train_labels),(test_data, test_labels) = reuters.load_data(num_words = 100000)\n",
        "# again we are only interested in the TOP10000 words"
      ],
      "metadata": {
        "id": "xSwdDbHafc7b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### not necessary"
      ],
      "metadata": {
        "id": "C8bzO2dsR5Fm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_data)"
      ],
      "metadata": {
        "id": "Z4HqHmWOgYXi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(test_data)"
      ],
      "metadata": {
        "id": "qWxvJq2Pgb1L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_labels)"
      ],
      "metadata": {
        "id": "EeI_QU-oSBUs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note that the format of the data is the same as in the previous case, where each piece of news is encode into a list of integers, being each of them correspondent to a word."
      ],
      "metadata": {
        "id": "24IDvjXrgjon"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Extra: decoding back to word (same as in imdb case)"
      ],
      "metadata": {
        "id": "LmL1OeTKhPAp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "word_index = reuters.get_word_index()    # dict that maps each word to its code number\n",
        "\n",
        "reverse_word_index = dict(            # dict inverting value and key (number to word)\n",
        "    [(value, key) for (key, value) in word_index.items()])\n",
        "\n",
        "# Decoding train_data[0]\n",
        "decoded_newswire = \" \".join(\n",
        "    [reverse_word_index.get(i - 3, \"?\") for i in train_data[0]])\n",
        "\n",
        "decoded_newswire"
      ],
      "metadata": {
        "id": "U6hfxk-qhY_K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Turning lists into tensors (same code as before)"
      ],
      "metadata": {
        "id": "73oC4_Hoh2jG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dont understand this error\n",
        "x_train = vectorize_sequences(train_data)\n",
        "x_test = vectorize_sequences(test_data)"
      ],
      "metadata": {
        "id": "yzikqK92h8sB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Vectorizing labels (diferent than in the previous case because there are more than 2 labels)\n",
        "\n",
        "def to_one_hot(labels, dimension=46):\n",
        "  results = np.zeros((len(labels), dimension))\n",
        "  for i, label in enumerate(labels):\n",
        "    results[i, label] = 1.\n",
        "  return results\n",
        "\n",
        "# this yields a matrix with 46 dimensions(columns),\n",
        "# where all values in a row are 0 except in the column with the number of the correct label\n",
        "\n",
        "y_train = to_one_hot(train_labels)\n",
        "y_test = to_one_hot(test_labels)"
      ],
      "metadata": {
        "id": "9p6Q5y7Oije1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# There is all this built in way to do it\n",
        "# from tensorflow.keras.utils import to_categorical\n",
        "# y_train = to_categorical(train_labels)\n",
        "# y_test = to_categorical(test_labels)"
      ],
      "metadata": {
        "id": "Eh4aH4sdj5NN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### CNN model"
      ],
      "metadata": {
        "id": "iFVwVyAtkbaP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max_features = 10000   # Define maximum number of words to consider in the vocabulary\n",
        "maxlen = 500           # Define sequence length (truncate or pad sequences to this length)\n",
        "embedding_dim = 128    # Embedding dimension\n",
        "\n",
        "# Create the model\n",
        "model_cnn = keras.Sequential([\n",
        "    # Embedding layer to convert word indices to dense vectors\n",
        "    layers.Embedding(input_dim=max_features, output_dim=embedding_dim, input_length=maxlen),\n",
        "\n",
        "    # 1D CNN layers for extracting n-gram features\n",
        "    layers.Conv1D(filters=128, kernel_size=5, activation='relu', padding='same'),\n",
        "    layers.MaxPooling1D(pool_size=5),\n",
        "    layers.Conv1D(filters=128, kernel_size=5, activation='relu', padding='same'),\n",
        "    layers.MaxPooling1D(pool_size=5),\n",
        "    layers.Conv1D(filters=128, kernel_size=5, activation='relu', padding='same'),\n",
        "    layers.GlobalMaxPooling1D(),\n",
        "\n",
        "    # Dense layers for classification\n",
        "    layers.Dense(128, activation='relu'),\n",
        "    layers.Dropout(0.5),  # Add dropout to reduce overfitting\n",
        "    layers.Dense(1, activation='sigmoid')  # Binary classification output\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model_cnn.compile(\n",
        "    optimizer='adam',\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# model.compile(optimizer=\"rmsprop\",            # choosing optimizer\n",
        "#               loss=\"binary_crossentropy\",     # choosing loss function\n",
        "#               metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "29hR64WZkyAR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's compute validation datasets."
      ],
      "metadata": {
        "id": "DtS6HaDxlxEL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Splitting train into partial_train and validation\n",
        "x_val = x_train[:10000]\n",
        "partial_x_train = x_train[10000:]\n",
        "\n",
        "y_val = y_train[:10000]\n",
        "partial_y_train = y_train[10000:]"
      ],
      "metadata": {
        "id": "AGA-zoVKl03Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's now train the model"
      ],
      "metadata": {
        "id": "w2odJi44l7LU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = model_cnn.fit(partial_x_train,\n",
        "                    partial_y_train,\n",
        "                    epochs=20,\n",
        "                    batch_size=512,\n",
        "                    validation_data=(x_val, y_val))"
      ],
      "metadata": {
        "id": "JzFKvXrll-SA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Plotting"
      ],
      "metadata": {
        "id": "W9jiMlIKoPKP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Loss\n",
        "history_dict = history.history\n",
        "loss_values = history_dict[\"loss\"]\n",
        "val_loss_values = history_dict[\"val_loss\"]\n",
        "epochs = range(1, len(loss_values) + 1)\n",
        "plt.plot(epochs, loss_values, \"bo\", label=\"Training loss\")\n",
        "plt.plot(epochs, val_loss_values, \"b\", label=\"Validation loss\")\n",
        "plt.title(\"Training and validation loss\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "8UZxX802oOdN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Accuracy\n",
        "plt.clf()\n",
        "acc = history_dict[\"accuracy\"]\n",
        "val_acc = history_dict[\"val_accuracy\"]\n",
        "plt.plot(epochs, acc, \"bo\", label=\"Training acc\")\n",
        "plt.plot(epochs, val_acc, \"b\", label=\"Validation acc\")\n",
        "plt.title(\"Training and validation accuracy\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "bX7gpa46oU1k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Transformer model"
      ],
      "metadata": {
        "id": "xk2W40LxlL75"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define parameters\n",
        "max_features = 10000  # Size of vocabulary\n",
        "maxlen = 500  # Max sequence length\n",
        "embedding_dim = 128  # Embedding dimension\n",
        "\n",
        "# Transformer block\n",
        "def transformer_encoder(inputs, head_size, num_heads, ff_dim, dropout=0):\n",
        "    # Multi-head self-attention\n",
        "    attention_output = layers.MultiHeadAttention(\n",
        "        num_heads=num_heads, key_dim=head_size\n",
        "    )(inputs, inputs)\n",
        "    attention_output = layers.Dropout(dropout)(attention_output)\n",
        "    attention_output = layers.LayerNormalization(epsilon=1e-6)(\n",
        "        inputs + attention_output\n",
        "    )\n",
        "\n",
        "    # Feed-forward network\n",
        "    ffn_output = layers.Dense(ff_dim, activation=\"relu\")(attention_output)\n",
        "    ffn_output = layers.Dense(inputs.shape[-1])(ffn_output)\n",
        "    ffn_output = layers.Dropout(dropout)(ffn_output)\n",
        "\n",
        "    # Second residual connection and layer normalization\n",
        "    return layers.LayerNormalization(epsilon=1e-6)(\n",
        "        attention_output + ffn_output\n",
        "    )\n",
        "\n",
        "# Define input\n",
        "inputs = layers.Input(shape=(maxlen,))\n",
        "\n",
        "# Embedding layer\n",
        "x = layers.Embedding(max_features, embedding_dim)(inputs)\n",
        "\n",
        "# Add positional encoding\n",
        "positions = tf.range(start=0, limit=maxlen, delta=1)\n",
        "position_embedding = layers.Embedding(\n",
        "    input_dim=maxlen, output_dim=embedding_dim\n",
        ")(positions)\n",
        "x = x + position_embedding\n",
        "\n",
        "# Apply dropout\n",
        "x = layers.Dropout(0.1)(x)\n",
        "\n",
        "# Apply transformer blocks\n",
        "transformer_blocks = 2\n",
        "for _ in range(transformer_blocks):\n",
        "    x = transformer_encoder(x, head_size=64, num_heads=2, ff_dim=128, dropout=0.1)\n",
        "\n",
        "# Pool across sequence dimension and apply classification layers\n",
        "x = layers.GlobalAveragePooling1D()(x)\n",
        "x = layers.Dense(64, activation=\"relu\")(x)\n",
        "x = layers.Dropout(0.1)(x)\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "\n",
        "# Build the model\n",
        "model_transf = keras.Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "# Compile the model\n",
        "model_transf.compile(\n",
        "    optimizer=\"adam\",\n",
        "    loss=\"binary_crossentropy\",\n",
        "    metrics=[\"accuracy\"]\n",
        ")"
      ],
      "metadata": {
        "id": "8AVEubDAlSBe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "history = model_transf.fit(\n",
        "    x_train, y_train,\n",
        "    batch_size=32,\n",
        "    epochs=5,\n",
        "    validation_split=0.2,\n",
        "    callbacks=[\n",
        "        keras.callbacks.EarlyStopping(monitor='val_loss', patience=2),\n",
        "        keras.callbacks.ModelCheckpoint('best_transformer_model.h5', save_best_only=True)\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "J9xUS4b-mc1x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_transf.summary()"
      ],
      "metadata": {
        "id": "23-camCroaF2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate on test set\n",
        "test_loss, test_acc = model_transf.evaluate(x_test, y_test)\n",
        "print(f'Test accuracy: {test_acc:.4f}')\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "KaFACX4Uon8h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Final model"
      ],
      "metadata": {
        "id": "l6SsxOwmVABX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# what does this do?\n",
        "import copy\n",
        "test_labels_copy = copy.copy(test_labels)\n",
        "np.random.shuffle(test_labels_copy)\n",
        "hits_array = np.array(test_labels) == np.array(test_labels_copy)\n",
        "hits_array.mean()"
      ],
      "metadata": {
        "id": "Gm8gWKZ0VhEe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Making predictions:"
      ],
      "metadata": {
        "id": "EKON4S1NV266"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = model.predict(x_test)"
      ],
      "metadata": {
        "id": "Vb_p_LU4VxSP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}